---
title:
author: "Alex Filazzola, Diego Sotomayor, Christopher Lortie"
date: "August 2016"
output:
  html_document:
    theme: yeti
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
---

## Micronet

Tracking the consequences of environmental change requires information on both the physical and biological characteristics of ecological systems. Large-scale environmental data are now widely available from many data repositories. However, these data sets often need to be down-scaled in order to be paired with local ecological measurements. Hence, micro-environmental sensors are sometimes useful to integrate scales of ecological information relevant to global change. This is an open-source, collaborative network of micro-environmental sensors deployed globally.

[micronet](http://micronet.io/)

[ecoblender](http://ecoblender.org)

![](./microimage.jpg)
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### load functions
```{r echo=TRUE}
# combine multiple csv files into one dataframe ###
concat <- function(fileList){
dflist <- data.frame() ## create empty dataframe
for(i in 1:length(fileList)){
loadfile<-read.csv(fileList[i]) ## read each csv file for loop
loggerID <- basename(fileList[i]) ## root file name
loggerID = substr(loggerID, 1, nchar(loggerID)-4) ## drop csv
loadfile[,"loggerID"] <- rep(loggerID,nrow(loadfile)) ## add logger ID to column
dflist<-rbind(dflist,loadfile) ## concatenate previous csv to main dataframe
}
return(dflist)
}

## calculates summary statistics of logger data
## includes minimum, maximum, mean, standard deviation, number of observations, start date of logger, end date of logger, duration of logger recording, and response variable.

summary.stat <- function(fileList, resp){
dflist <- data.frame() ## create empty dataframe
## combine into one dataframe
for(i in 1:length(fileList)){
loadfile<-read.csv(fileList[i]) ## read each csv file for loop
loggerID <- basename(fileList[i]) ## root file name
loggerID = substr(loggerID, 1, nchar(loggerID)-4) ## drop csv
## add detailed time statistics
t.str <- strptime(loadfile[,"Date"], "%m/%d/%Y %H:%M")
loadfile[,"days"] <- as.Date(format(t.str, "%m/%d/%Y"), "%m/%d/%Y") ## separate date
loadfile[,"hours"] <- as.numeric(format(t.str, "%H")) ##specify hour logged
loadfile[,"minutes"] <- as.numeric(format(t.str, "%M")) ## specify minutes logged
obs <- nrow(loadfile) ## number of observations
start.date <- min(loadfile[,"days"]) ## day logger first started
end.date <- max(loadfile[,"days"]) ## day logger ended
duration <- as.numeric(difftime(end.date,start.date)) ## duration of logger activity
resp.stat <- function(fileList, resp){
resp.min <- min(fileList[,resp]) ## minimum of response
resp.max <- max(fileList[,resp]) ## maximum of response
resp.mean <- mean(fileList[,resp]) ## mean of response
resp.sd <- mean(fileList[,resp]) ## standard deviation of response
sum.stat <- data.frame(resp.min,resp.max,resp.mean,resp.sd,obs,start.date,end.date,duration,resp)
colnames(sum.stat) <- c("min","max","mean","sd","observations","start.date","end.date","duration","Response")
return(sum.stat)
}
sum.stat <- resp.stat(loadfile, resp)
sum.stat[,"loggerID"] <- loggerID
dflist <- rbind(dflist, sum.stat)
}
return(dflist)
}

## error bar functions
source("errorbar.functions.r")
```

### summary stats on sample data
```{r}

## load hobo data files
fileList<-list.files("sample.data\\",pattern=".csv$",full=T)

## view file list
fileList

## extract summary statistics of light data
Temp.summary <- summary.stat(fileList, "Temperature")
Luxavg.summary <- summary.stat(fileList, "Avg.light")
Luxmax.summary <- summary.stat(fileList, "Max.light")
Total.summary <- rbind(Temp.summary,Luxavg.summary,Luxmax.summary)
Total.summary
```

### combining multiple dataframes
```{r}
data.hobo <- concat(fileList)
str(data.hobo)
head(data.hobo,10)
tail(data.hobo,10)
```

### separate hours from the date column
``` {r}
## separate date from hours and minutes
t.str <- strptime(data.hobo[,"Date"], "%m/%d/%Y %H:%M") ## format is month/day/year hour:minute
data.hobo[,"days"] <- as.Date(format(t.str, "%m/%d/%Y"), "%m/%d/%Y") ## separate date
data.hobo[,"hours"] <- as.numeric(format(t.str, "%H")) ##specify hour logged
data.hobo[,"minutes"] <- as.numeric(format(t.str, "%M")) ## specify minutes logged
head(data.hobo, 10)
```
### extracting specific statistics
```{r warning=FALSE, message=FALSE}
library(dplyr)
## extract mean and standard error for loggers and hour of day
data.hourly <- data.hobo %>% group_by(loggerID, hours)  %>%  summarise(Temp=mean(Temperature),Light=mean(Avg.light),Temp.se=se(Temperature),Light.se=se(Avg.light))
data.hourly <- data.frame(data.hourly)

data.hourly
```

### plot 
``` {r fig.width=8}
## select one logger to plot
Carrot.logger <- subset(data.hourly, loggerID=="Carrot")
par(mfrow=c(1,2)) ## side by side plots

## plot the light radiation on average for each hour of the day during the season
plot(Carrot.logger[,"hours"],Carrot.logger[,"Light"], pch=21, bg="White", ylab="Light (lux)", xlab="hour of the day", ylim=c(0,65000))
error.bar(Carrot.logger[,"hours"],Carrot.logger[,"Light"],Carrot.logger[,"Light.se"])
points(Carrot.logger[,"hours"],Carrot.logger[,"Light"], pch=21, bg="White") ## repeat to cover lines

## plot the temperature on average for each hour of the day during the season
plot(Carrot.logger[,"hours"],Carrot.logger[,"Temp"], pch=21, bg="Black", ylab="Temperature (CÂ°)", xlab="hour of the day", ylim=c(12,28))
error.bar(Carrot.logger[,"hours"],Carrot.logger[,"Temp"],Carrot.logger[,"Temp.se"])
```

### selecting for time frames
```{r}
## subset for mid day temperatures and light
mid.day <- subset(data.hobo, hours < 16 & hours > 8) #between 10-14
##summarize mid day values
mid.day.means <- mid.day %>% group_by(loggerID)  %>%  summarise(Temp=mean(Temperature),Light=mean(Avg.light),Temp.se=se(Temperature),Light.se=se(Avg.light))
mid.day.means <- data.frame(mid.day.means)
mid.day.means

```


